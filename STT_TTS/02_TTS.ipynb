{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3823abe4",
   "metadata": {},
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db847ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 불러오기\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04581f89",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649c50a",
   "metadata": {},
   "source": [
    "### 텍스트 -> 오디오 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1e6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 저장할 파일 경로\n",
    "speech_file_path = \"./resources/speech.mp3\"\n",
    "\n",
    "# OpenAI 클라이언트 생성\n",
    "client = OpenAI()\n",
    "\n",
    "# 음성 합성 요청\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"안녕하세요 반가워요\",\n",
    "    instructions=\"굵은 남자 목소리\"\n",
    ") as response:\n",
    "    # 음성 합성 결과를 파일로 저장\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "# 파일 경로\n",
    "audio_path = \"./resources/speech.mp3\"  \n",
    "\n",
    "# 오디오 파일 재생\n",
    "playsound(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836aa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# mp3 파일일 경우\n",
    "sound = AudioSegment.from_mp3(\"./resources/speech.mp3\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac758c0",
   "metadata": {},
   "source": [
    "## ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4500db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "# ElevenLabs 클라이언트 생성\n",
    "client = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d9db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice_id='S8IIf77q99OgYuPS5P9n' name='고윤정' samples=[VoiceSample(sample_id='lQtqkZpFcLnPRVaJowMO', file_name='고윤정.mp3', mime_type='audio/mpeg', size_bytes=422693, hash='beb75cd9e896e59985c758c42cd85c3f', duration_secs=17.568412698412697, remove_background_noise=None, has_isolated_audio=None, has_isolated_audio_preview=None, speaker_separation=None, trim_start=None, trim_end=None)] category='cloned' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=False, state={}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language=None, progress={}, message={}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=None, next_max_verification_attempts_reset_unix_ms=None, finetuning_state=None) labels={'language': 'ko'} description='ESQUIRE Korea 고윤정 인터뷰 중 일부' preview_url='https://storage.googleapis.com/eleven-public-prod/database/user/oxRC0IqrnAU2oQkVftSNUHsufAT2/voices/S8IIf77q99OgYuPS5P9n/f75c5276-582a-45ba-9a58-3acb9ca1dcf0.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=[] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource='admin' is_owner=True is_legacy=False is_mixed=False created_at_unix=1748269329\n",
      "voice_id='YCPBwhY4tRbx9FF87DRi' name='koohyesun' samples=[VoiceSample(sample_id='ezQoDbKvjFGObBTfcRiG', file_name='audio11.mp3', mime_type='audio/mpeg', size_bytes=220098, hash='8bde49e10241c1d3540c44bd1fca8768', duration_secs=13.7, remove_background_noise=None, has_isolated_audio=None, has_isolated_audio_preview=None, speaker_separation=None, trim_start=None, trim_end=None)] category='cloned' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=False, state={}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language=None, progress={}, message={}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=None, next_max_verification_attempts_reset_unix_ms=None, finetuning_state=None) labels={'language': 'ko'} description='오은영의 상담소에서 구혜선의 음성' preview_url='https://storage.googleapis.com/eleven-public-prod/database/user/oxRC0IqrnAU2oQkVftSNUHsufAT2/voices/YCPBwhY4tRbx9FF87DRi/b474239f-3158-4ee7-9a3b-355d851225ec.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=[] verified_languages=[] safety_control='NONE' voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource='admin' is_owner=True is_legacy=False is_mixed=False created_at_unix=1747383895\n",
      "voice_id='21m00Tcm4TlvDq8ikWAM' name='Rachel' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=False, state={}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language=None, progress={}, message={}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=None, next_max_verification_attempts_reset_unix_ms=None, finetuning_state=None) labels={'accent': 'american', 'description': 'calm', 'age': 'young', 'gender': 'female', 'use_case': 'narration'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/21m00Tcm4TlvDq8ikWAM/b4928a68-c03b-411f-8533-3d5c299fd451.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=[] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='29vD33N1CtxCmqQRPOHJ' name='Drew' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_multilingual_v2': 'fine_tuned', 'eleven_turbo_v2_5': 'fine_tuned', 'eleven_flash_v2_5': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_multilingual_v2': '', 'eleven_turbo_v2_5': '', 'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_v2_5_flash': 'Done!', 'eleven_turbo_v2': '', 'eleven_flash_v2': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': 'american', 'description': 'well-rounded', 'age': 'middle_aged', 'gender': 'male', 'use_case': 'news'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/29vD33N1CtxCmqQRPOHJ/b99fc51d-12d3-4312-b480-a8a45a7d51ef.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='2EiwWnXFnvU5JabPnv8n' name='Clyde' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_flash_v2_5': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_multilingual_v2': '', 'eleven_turbo_v2_5': '', 'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_v2_5_flash': 'Done!', 'eleven_turbo_v2': '', 'eleven_flash_v2': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': 'american', 'description': 'war veteran', 'age': 'middle_aged', 'gender': 'male', 'use_case': 'characters'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/2EiwWnXFnvU5JabPnv8n/65d80f52-703f-4cae-a91d-75d4e200ed02.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_multilingual_v1', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='5Q0t7uMcjvnagumLfvZi' name='Paul' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_multilingual_v2': 'fine_tuned', 'eleven_turbo_v2_5': 'fine_tuned', 'eleven_flash_v2_5': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_multilingual_v2': '', 'eleven_turbo_v2_5': '', 'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_v2_5_flash': 'Done!', 'eleven_turbo_v2': '', 'eleven_flash_v2': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': 'american', 'description': 'authoritative', 'age': 'middle_aged', 'gender': 'male', 'use_case': 'news'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/5Q0t7uMcjvnagumLfvZi/a4aaa30e-54c4-44a4-8e46-b9b00505d963.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='9BWtsMINqrJLrRacOk9x' name='Aria' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_multilingual_v2': 'fine_tuned', 'eleven_turbo_v2_5': 'fine_tuned', 'eleven_flash_v2_5': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_flash_v2': 'Done!', 'eleven_v2_5_flash': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': 'american', 'descriptive': 'husky', 'age': 'middle_aged', 'gender': 'female', 'language': 'en', 'use_case': 'informative_educational'} description='A middle-aged female with an African-American accent. Calm with a hint of rasp.' preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_v2_flash', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_flash_v2', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_turbo_v2_5', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_multilingual_v2', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_v2_5_flash', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_flash_v2_5', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_turbo_v2', accent='american', locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/405766b8-1f4e-4d3c-aba1-6f25333823ec.mp3'), VerifiedVoiceLanguageResponseModel(language='fr', model_id='eleven_multilingual_v2', accent='standard', locale='fr-FR', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/ae97c224-d4d0-4e03-a9ab-36f031f48e94.mp3'), VerifiedVoiceLanguageResponseModel(language='zh', model_id='eleven_multilingual_v2', accent='standard', locale='cmn-CN', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/b6a58993-1cf7-4ea8-b3b1-a60b3641d5bf.mp3'), VerifiedVoiceLanguageResponseModel(language='tr', model_id='eleven_multilingual_v2', accent='standard', locale='tr-TR', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/9BWtsMINqrJLrRacOk9x/9342915e-dd15-4a11-af37-96670decd65a.mp3')] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=False is_mixed=False created_at_unix=None\n",
      "voice_id='AZnzlk1XvdvUeBnXmlld' name='Domi' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=False, state={}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language=None, progress={}, message={}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=None, next_max_verification_attempts_reset_unix_ms=None, finetuning_state=None) labels={'accent': 'american', 'description': 'strong', 'age': 'young', 'gender': 'female', 'use_case': 'narration'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/AZnzlk1XvdvUeBnXmlld/b3c36b01-f80d-4b16-a698-f83682dee84c.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=[] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='CYw3kZ02Hs0563khs1Fj' name='Dave' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_flash_v2_5': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_multilingual_v2': '', 'eleven_turbo_v2_5': '', 'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_v2_5_flash': 'Done!', 'eleven_turbo_v2': '', 'eleven_flash_v2': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': 'british', 'description': 'conversational', 'age': 'young', 'gender': 'male', 'use_case': 'characters'} description=None preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CYw3kZ02Hs0563khs1Fj/872cb056-45d3-419e-b5c6-de2b387a93a0.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_multilingual_v1', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n",
      "voice_id='CwhRBWXzGAHq8TQ4Fs17' name='Roger' samples=None category='premade' fine_tuning=FineTuningResponse(is_allowed_to_fine_tune=True, state={'eleven_multilingual_v2': 'fine_tuned', 'eleven_turbo_v2_5': 'failed', 'eleven_flash_v2_5': 'fine_tuned', 'eleven_v2_flash': 'fine_tuned', 'eleven_v2_5_flash': 'fine_tuned', 'eleven_turbo_v2': 'fine_tuned', 'eleven_flash_v2': 'fine_tuned'}, verification_failures=[], verification_attempts_count=0, manual_verification_requested=False, language='en', progress={'eleven_flash_v2_5': 1.0, 'eleven_v2_flash': 1.0, 'eleven_flash_v2': 1.0, 'eleven_v2_5_flash': 1.0}, message={'eleven_flash_v2_5': 'Done!', 'eleven_v2_flash': 'Done!', 'eleven_flash_v2': 'Done!', 'eleven_v2_5_flash': 'Done!'}, dataset_duration_seconds=None, verification_attempts=None, slice_ids=None, manual_verification=None, max_verification_attempts=5, next_max_verification_attempts_reset_unix_ms=1700000000000, finetuning_state=None) labels={'accent': '', 'description': 'confident', 'age': 'middle_aged', 'gender': 'male', 'language': 'en', 'use_case': 'social media'} description='' preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3' available_for_tiers=[] settings=None sharing=None high_quality_base_model_ids=['eleven_v2_flash', 'eleven_flash_v2', 'eleven_turbo_v2_5', 'eleven_multilingual_v2', 'eleven_v2_5_flash', 'eleven_flash_v2_5', 'eleven_turbo_v2'] verified_languages=[VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_v2_flash', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_flash_v2', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_turbo_v2_5', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_multilingual_v2', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_v2_5_flash', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_flash_v2_5', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='en', model_id='eleven_turbo_v2', accent=None, locale='en-US', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/58ee3ff5-f6f2-4628-93b8-e38eb31806b0.mp3'), VerifiedVoiceLanguageResponseModel(language='fr', model_id='eleven_multilingual_v2', accent='standard', locale='fr-FR', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/042d9b70-5927-4630-985e-e95107b74ec2.mp3'), VerifiedVoiceLanguageResponseModel(language='de', model_id='eleven_multilingual_v2', accent='standard', locale='de-DE', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/fa6a7658-18a9-4634-a96f-95dc3c47629d.mp3'), VerifiedVoiceLanguageResponseModel(language='nl', model_id='eleven_multilingual_v2', accent='standard', locale='nl-NL', preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/12a2ba8b-4fb3-44b6-9bc7-da0afd076fc9.mp3'), VerifiedVoiceLanguageResponseModel(language='es', model_id='eleven_multilingual_v2', accent='standard', locale=None, preview_url='https://storage.googleapis.com/eleven-public-prod/premade/voices/CwhRBWXzGAHq8TQ4Fs17/f172f037-5e23-44ea-a08e-56ddb6447d5b.mp3')] safety_control=None voice_verification=VoiceVerificationResponse(requires_verification=False, is_verified=False, verification_failures=[], verification_attempts_count=0, language=None, verification_attempts=None) permission_on_resource=None is_owner=False is_legacy=True is_mixed=False created_at_unix=None\n"
     ]
    }
   ],
   "source": [
    "# 음성 목록 가져오기\n",
    "response = client.voices.search()\n",
    "\n",
    "for voice in response.voices:\n",
    "    print(voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbeab01",
   "metadata": {},
   "source": [
    "### 텍스트 -> 오디오 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d9ffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mp3 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 음성 합성\n",
    "audio = client.text_to_speech.convert(\n",
    "    text=\"좋은 하루 되세요\",\n",
    "    voice_id=\"S8IIf77q99OgYuPS5P9n\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    "    voice_settings={\n",
    "        \"stability\": 0.3,\n",
    "        \"similarity_boost\": 0.8,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# 파일 경로\n",
    "audio_path = \"./resources/voice_clone_고윤정.mp3\" \n",
    "\n",
    "# 음성 합성 결과를 파일로 저장\n",
    "audio_bytes = b\"\".join(audio)\n",
    "\n",
    "with open(audio_path, \"wb\") as f:\n",
    "    f.write(audio_bytes)\n",
    "    print(\"✅ mp3 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "314406de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import play\n",
    "\n",
    "# 음성 재생\n",
    "play(audio_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d45ec",
   "metadata": {},
   "source": [
    "## Coqui XTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce16b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TTS\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get device\u001b[39;00m\n\u001b[32m      5\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\TTS\\__init__.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_configs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDatasetConfig\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfigs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XttsConfig\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XttsArgs, XttsAudioConfig\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mradam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RAdam\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\TTS\\tts\\configs\\xtts_config.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfigs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_configs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTTSConfig\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XttsArgs, XttsAudioConfig\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mXttsConfig\u001b[39;00m(BaseTTSConfig):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Defines parameters for XTTS TTS model.\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m \u001b[33;03m        >>> config = XttsConfig()\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\TTS\\tts\\models\\xtts.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcoqpit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Coqpit\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_fsspec\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgpt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhifigan_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HifiDecoder\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstream_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_stream_support\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\TTS\\tts\\layers\\xtts\\gpt.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2Config\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtortoise\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautoregressive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     ConditioningEncoder,\n\u001b[32m     12\u001b[39m     LearnedPositionEmbeddings,\n\u001b[32m     13\u001b[39m     _prepare_attention_mask_for_generation,\n\u001b[32m     14\u001b[39m     build_hf_gpt_transformer,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTTS\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxtts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgpt_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2InferenceModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1953\u001b[39m     value = Placeholder\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1956\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1965\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1969\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1970\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1971\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1972\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\NCACH\\.venv\\Lib\\site-packages\\transformers\\models\\__init__.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     albert,\n\u001b[32m     17\u001b[39m     align,\n\u001b[32m     18\u001b[39m     altclip,\n\u001b[32m     19\u001b[39m     aria,\n\u001b[32m     20\u001b[39m     audio_spectrogram_transformer,\n\u001b[32m     21\u001b[39m     auto,\n\u001b[32m     22\u001b[39m     autoformer,\n\u001b[32m     23\u001b[39m     aya_vision,\n\u001b[32m     24\u001b[39m     bamba,\n\u001b[32m     25\u001b[39m     bark,\n\u001b[32m     26\u001b[39m     bart,\n\u001b[32m     27\u001b[39m     barthez,\n\u001b[32m     28\u001b[39m     bartpho,\n\u001b[32m     29\u001b[39m     beit,\n\u001b[32m     30\u001b[39m     bert,\n\u001b[32m     31\u001b[39m     bert_generation,\n\u001b[32m     32\u001b[39m     bert_japanese,\n\u001b[32m     33\u001b[39m     bertweet,\n\u001b[32m     34\u001b[39m     big_bird,\n\u001b[32m     35\u001b[39m     bigbird_pegasus,\n\u001b[32m     36\u001b[39m     biogpt,\n\u001b[32m     37\u001b[39m     bit,\n\u001b[32m     38\u001b[39m     blenderbot,\n\u001b[32m     39\u001b[39m     blenderbot_small,\n\u001b[32m     40\u001b[39m     blip,\n\u001b[32m     41\u001b[39m     blip_2,\n\u001b[32m     42\u001b[39m     bloom,\n\u001b[32m     43\u001b[39m     bridgetower,\n\u001b[32m     44\u001b[39m     bros,\n\u001b[32m     45\u001b[39m     byt5,\n\u001b[32m     46\u001b[39m     camembert,\n\u001b[32m     47\u001b[39m     canine,\n\u001b[32m     48\u001b[39m     chameleon,\n\u001b[32m     49\u001b[39m     chinese_clip,\n\u001b[32m     50\u001b[39m     clap,\n\u001b[32m     51\u001b[39m     clip,\n\u001b[32m     52\u001b[39m     clipseg,\n\u001b[32m     53\u001b[39m     clvp,\n\u001b[32m     54\u001b[39m     code_llama,\n\u001b[32m     55\u001b[39m     codegen,\n\u001b[32m     56\u001b[39m     cohere,\n\u001b[32m     57\u001b[39m     cohere2,\n\u001b[32m     58\u001b[39m     colpali,\n\u001b[32m     59\u001b[39m     conditional_detr,\n\u001b[32m     60\u001b[39m     convbert,\n\u001b[32m     61\u001b[39m     convnext,\n\u001b[32m     62\u001b[39m     convnextv2,\n\u001b[32m     63\u001b[39m     cpm,\n\u001b[32m     64\u001b[39m     cpmant,\n\u001b[32m     65\u001b[39m     ctrl,\n\u001b[32m     66\u001b[39m     cvt,\n\u001b[32m     67\u001b[39m     dab_detr,\n\u001b[32m     68\u001b[39m     dac,\n\u001b[32m     69\u001b[39m     data2vec,\n\u001b[32m     70\u001b[39m     dbrx,\n\u001b[32m     71\u001b[39m     deberta,\n\u001b[32m     72\u001b[39m     deberta_v2,\n\u001b[32m     73\u001b[39m     decision_transformer,\n\u001b[32m     74\u001b[39m     deepseek_v3,\n\u001b[32m     75\u001b[39m     deformable_detr,\n\u001b[32m     76\u001b[39m     deit,\n\u001b[32m     77\u001b[39m     deprecated,\n\u001b[32m     78\u001b[39m     depth_anything,\n\u001b[32m     79\u001b[39m     depth_pro,\n\u001b[32m     80\u001b[39m     detr,\n\u001b[32m     81\u001b[39m     dialogpt,\n\u001b[32m     82\u001b[39m     diffllama,\n\u001b[32m     83\u001b[39m     dinat,\n\u001b[32m     84\u001b[39m     dinov2,\n\u001b[32m     85\u001b[39m     dinov2_with_registers,\n\u001b[32m     86\u001b[39m     distilbert,\n\u001b[32m     87\u001b[39m     dit,\n\u001b[32m     88\u001b[39m     donut,\n\u001b[32m     89\u001b[39m     dpr,\n\u001b[32m     90\u001b[39m     dpt,\n\u001b[32m     91\u001b[39m     efficientnet,\n\u001b[32m     92\u001b[39m     electra,\n\u001b[32m     93\u001b[39m     emu3,\n\u001b[32m     94\u001b[39m     encodec,\n\u001b[32m     95\u001b[39m     encoder_decoder,\n\u001b[32m     96\u001b[39m     ernie,\n\u001b[32m     97\u001b[39m     esm,\n\u001b[32m     98\u001b[39m     falcon,\n\u001b[32m     99\u001b[39m     falcon_mamba,\n\u001b[32m    100\u001b[39m     fastspeech2_conformer,\n\u001b[32m    101\u001b[39m     flaubert,\n\u001b[32m    102\u001b[39m     flava,\n\u001b[32m    103\u001b[39m     fnet,\n\u001b[32m    104\u001b[39m     focalnet,\n\u001b[32m    105\u001b[39m     fsmt,\n\u001b[32m    106\u001b[39m     funnel,\n\u001b[32m    107\u001b[39m     fuyu,\n\u001b[32m    108\u001b[39m     gemma,\n\u001b[32m    109\u001b[39m     gemma2,\n\u001b[32m    110\u001b[39m     gemma3,\n\u001b[32m    111\u001b[39m     git,\n\u001b[32m    112\u001b[39m     glm,\n\u001b[32m    113\u001b[39m     glm4,\n\u001b[32m    114\u001b[39m     glpn,\n\u001b[32m    115\u001b[39m     got_ocr2,\n\u001b[32m    116\u001b[39m     gpt2,\n\u001b[32m    117\u001b[39m     gpt_bigcode,\n\u001b[32m    118\u001b[39m     gpt_neo,\n\u001b[32m    119\u001b[39m     gpt_neox,\n\u001b[32m    120\u001b[39m     gpt_neox_japanese,\n\u001b[32m    121\u001b[39m     gpt_sw3,\n\u001b[32m    122\u001b[39m     gptj,\n\u001b[32m    123\u001b[39m     granite,\n\u001b[32m    124\u001b[39m     granitemoe,\n\u001b[32m    125\u001b[39m     granitemoeshared,\n\u001b[32m    126\u001b[39m     grounding_dino,\n\u001b[32m    127\u001b[39m     groupvit,\n\u001b[32m    128\u001b[39m     helium,\n\u001b[32m    129\u001b[39m     herbert,\n\u001b[32m    130\u001b[39m     hiera,\n\u001b[32m    131\u001b[39m     hubert,\n\u001b[32m    132\u001b[39m     ibert,\n\u001b[32m    133\u001b[39m     idefics,\n\u001b[32m    134\u001b[39m     idefics2,\n\u001b[32m    135\u001b[39m     idefics3,\n\u001b[32m    136\u001b[39m     ijepa,\n\u001b[32m    137\u001b[39m     imagegpt,\n\u001b[32m    138\u001b[39m     informer,\n\u001b[32m    139\u001b[39m     instructblip,\n\u001b[32m    140\u001b[39m     instructblipvideo,\n\u001b[32m    141\u001b[39m     jamba,\n\u001b[32m    142\u001b[39m     jetmoe,\n\u001b[32m    143\u001b[39m     kosmos2,\n\u001b[32m    144\u001b[39m     layoutlm,\n\u001b[32m    145\u001b[39m     layoutlmv2,\n\u001b[32m    146\u001b[39m     layoutlmv3,\n\u001b[32m    147\u001b[39m     layoutxlm,\n\u001b[32m    148\u001b[39m     led,\n\u001b[32m    149\u001b[39m     levit,\n\u001b[32m    150\u001b[39m     lilt,\n\u001b[32m    151\u001b[39m     llama,\n\u001b[32m    152\u001b[39m     llama4,\n\u001b[32m    153\u001b[39m     llava,\n\u001b[32m    154\u001b[39m     llava_next,\n\u001b[32m    155\u001b[39m     llava_next_video,\n\u001b[32m    156\u001b[39m     llava_onevision,\n\u001b[32m    157\u001b[39m     longformer,\n\u001b[32m    158\u001b[39m     longt5,\n\u001b[32m    159\u001b[39m     luke,\n\u001b[32m    160\u001b[39m     lxmert,\n\u001b[32m    161\u001b[39m     m2m_100,\n\u001b[32m    162\u001b[39m     mamba,\n\u001b[32m    163\u001b[39m     mamba2,\n\u001b[32m    164\u001b[39m     marian,\n\u001b[32m    165\u001b[39m     markuplm,\n\u001b[32m    166\u001b[39m     mask2former,\n\u001b[32m    167\u001b[39m     maskformer,\n\u001b[32m    168\u001b[39m     mbart,\n\u001b[32m    169\u001b[39m     mbart50,\n\u001b[32m    170\u001b[39m     megatron_bert,\n\u001b[32m    171\u001b[39m     megatron_gpt2,\n\u001b[32m    172\u001b[39m     mgp_str,\n\u001b[32m    173\u001b[39m     mimi,\n\u001b[32m    174\u001b[39m     mistral,\n\u001b[32m    175\u001b[39m     mistral3,\n\u001b[32m    176\u001b[39m     mixtral,\n\u001b[32m    177\u001b[39m     mllama,\n\u001b[32m    178\u001b[39m     mluke,\n\u001b[32m    179\u001b[39m     mobilebert,\n\u001b[32m    180\u001b[39m     mobilenet_v1,\n\u001b[32m    181\u001b[39m     mobilenet_v2,\n\u001b[32m    182\u001b[39m     mobilevit,\n\u001b[32m    183\u001b[39m     mobilevitv2,\n\u001b[32m    184\u001b[39m     modernbert,\n\u001b[32m    185\u001b[39m     moonshine,\n\u001b[32m    186\u001b[39m     moshi,\n\u001b[32m    187\u001b[39m     mpnet,\n\u001b[32m    188\u001b[39m     mpt,\n\u001b[32m    189\u001b[39m     mra,\n\u001b[32m    190\u001b[39m     mt5,\n\u001b[32m    191\u001b[39m     musicgen,\n\u001b[32m    192\u001b[39m     musicgen_melody,\n\u001b[32m    193\u001b[39m     mvp,\n\u001b[32m    194\u001b[39m     myt5,\n\u001b[32m    195\u001b[39m     nemotron,\n\u001b[32m    196\u001b[39m     nllb,\n\u001b[32m    197\u001b[39m     nllb_moe,\n\u001b[32m    198\u001b[39m     nougat,\n\u001b[32m    199\u001b[39m     nystromformer,\n\u001b[32m    200\u001b[39m     olmo,\n\u001b[32m    201\u001b[39m     olmo2,\n\u001b[32m    202\u001b[39m     olmoe,\n\u001b[32m    203\u001b[39m     omdet_turbo,\n\u001b[32m    204\u001b[39m     oneformer,\n\u001b[32m    205\u001b[39m     openai,\n\u001b[32m    206\u001b[39m     opt,\n\u001b[32m    207\u001b[39m     owlv2,\n\u001b[32m    208\u001b[39m     owlvit,\n\u001b[32m    209\u001b[39m     paligemma,\n\u001b[32m    210\u001b[39m     patchtsmixer,\n\u001b[32m    211\u001b[39m     patchtst,\n\u001b[32m    212\u001b[39m     pegasus,\n\u001b[32m    213\u001b[39m     pegasus_x,\n\u001b[32m    214\u001b[39m     perceiver,\n\u001b[32m    215\u001b[39m     persimmon,\n\u001b[32m    216\u001b[39m     phi,\n\u001b[32m    217\u001b[39m     phi3,\n\u001b[32m    218\u001b[39m     phi4_multimodal,\n\u001b[32m    219\u001b[39m     phimoe,\n\u001b[32m    220\u001b[39m     phobert,\n\u001b[32m    221\u001b[39m     pix2struct,\n\u001b[32m    222\u001b[39m     pixtral,\n\u001b[32m    223\u001b[39m     plbart,\n\u001b[32m    224\u001b[39m     poolformer,\n\u001b[32m    225\u001b[39m     pop2piano,\n\u001b[32m    226\u001b[39m     prompt_depth_anything,\n\u001b[32m    227\u001b[39m     prophetnet,\n\u001b[32m    228\u001b[39m     pvt,\n\u001b[32m    229\u001b[39m     pvt_v2,\n\u001b[32m    230\u001b[39m     qwen2,\n\u001b[32m    231\u001b[39m     qwen2_5_vl,\n\u001b[32m    232\u001b[39m     qwen2_audio,\n\u001b[32m    233\u001b[39m     qwen2_moe,\n\u001b[32m    234\u001b[39m     qwen2_vl,\n\u001b[32m    235\u001b[39m     qwen3,\n\u001b[32m    236\u001b[39m     qwen3_moe,\n\u001b[32m    237\u001b[39m     rag,\n\u001b[32m    238\u001b[39m     recurrent_gemma,\n\u001b[32m    239\u001b[39m     reformer,\n\u001b[32m    240\u001b[39m     regnet,\n\u001b[32m    241\u001b[39m     rembert,\n\u001b[32m    242\u001b[39m     resnet,\n\u001b[32m    243\u001b[39m     roberta,\n\u001b[32m    244\u001b[39m     roberta_prelayernorm,\n\u001b[32m    245\u001b[39m     roc_bert,\n\u001b[32m    246\u001b[39m     roformer,\n\u001b[32m    247\u001b[39m     rt_detr,\n\u001b[32m    248\u001b[39m     rt_detr_v2,\n\u001b[32m    249\u001b[39m     rwkv,\n\u001b[32m    250\u001b[39m     sam,\n\u001b[32m    251\u001b[39m     seamless_m4t,\n\u001b[32m    252\u001b[39m     seamless_m4t_v2,\n\u001b[32m    253\u001b[39m     segformer,\n\u001b[32m    254\u001b[39m     seggpt,\n\u001b[32m    255\u001b[39m     sew,\n\u001b[32m    256\u001b[39m     sew_d,\n\u001b[32m    257\u001b[39m     shieldgemma2,\n\u001b[32m    258\u001b[39m     siglip,\n\u001b[32m    259\u001b[39m     siglip2,\n\u001b[32m    260\u001b[39m     smolvlm,\n\u001b[32m    261\u001b[39m     speech_encoder_decoder,\n\u001b[32m    262\u001b[39m     speech_to_text,\n\u001b[32m    263\u001b[39m     speecht5,\n\u001b[32m    264\u001b[39m     splinter,\n\u001b[32m    265\u001b[39m     squeezebert,\n\u001b[32m    266\u001b[39m     stablelm,\n\u001b[32m    267\u001b[39m     starcoder2,\n\u001b[32m    268\u001b[39m     superglue,\n\u001b[32m    269\u001b[39m     superpoint,\n\u001b[32m    270\u001b[39m     swiftformer,\n\u001b[32m    271\u001b[39m     swin,\n\u001b[32m    272\u001b[39m     swin2sr,\n\u001b[32m    273\u001b[39m     swinv2,\n\u001b[32m    274\u001b[39m     switch_transformers,\n\u001b[32m    275\u001b[39m     t5,\n\u001b[32m    276\u001b[39m     table_transformer,\n\u001b[32m    277\u001b[39m     tapas,\n\u001b[32m    278\u001b[39m     textnet,\n\u001b[32m    279\u001b[39m     time_series_transformer,\n\u001b[32m    280\u001b[39m     timesformer,\n\u001b[32m    281\u001b[39m     timm_backbone,\n\u001b[32m    282\u001b[39m     timm_wrapper,\n\u001b[32m    283\u001b[39m     trocr,\n\u001b[32m    284\u001b[39m     tvp,\n\u001b[32m    285\u001b[39m     udop,\n\u001b[32m    286\u001b[39m     umt5,\n\u001b[32m    287\u001b[39m     unispeech,\n\u001b[32m    288\u001b[39m     unispeech_sat,\n\u001b[32m    289\u001b[39m     univnet,\n\u001b[32m    290\u001b[39m     upernet,\n\u001b[32m    291\u001b[39m     video_llava,\n\u001b[32m    292\u001b[39m     videomae,\n\u001b[32m    293\u001b[39m     vilt,\n\u001b[32m    294\u001b[39m     vipllava,\n\u001b[32m    295\u001b[39m     vision_encoder_decoder,\n\u001b[32m    296\u001b[39m     vision_text_dual_encoder,\n\u001b[32m    297\u001b[39m     visual_bert,\n\u001b[32m    298\u001b[39m     vit,\n\u001b[32m    299\u001b[39m     vit_mae,\n\u001b[32m    300\u001b[39m     vit_msn,\n\u001b[32m    301\u001b[39m     vitdet,\n\u001b[32m    302\u001b[39m     vitmatte,\n\u001b[32m    303\u001b[39m     vitpose,\n\u001b[32m    304\u001b[39m     vitpose_backbone,\n\u001b[32m    305\u001b[39m     vits,\n\u001b[32m    306\u001b[39m     vivit,\n\u001b[32m    307\u001b[39m     wav2vec2,\n\u001b[32m    308\u001b[39m     wav2vec2_bert,\n\u001b[32m    309\u001b[39m     wav2vec2_conformer,\n\u001b[32m    310\u001b[39m     wav2vec2_phoneme,\n\u001b[32m    311\u001b[39m     wav2vec2_with_lm,\n\u001b[32m    312\u001b[39m     wavlm,\n\u001b[32m    313\u001b[39m     whisper,\n\u001b[32m    314\u001b[39m     x_clip,\n\u001b[32m    315\u001b[39m     xglm,\n\u001b[32m    316\u001b[39m     xlm,\n\u001b[32m    317\u001b[39m     xlm_roberta,\n\u001b[32m    318\u001b[39m     xlm_roberta_xl,\n\u001b[32m    319\u001b[39m     xlnet,\n\u001b[32m    320\u001b[39m     xmod,\n\u001b[32m    321\u001b[39m     yolos,\n\u001b[32m    322\u001b[39m     yoso,\n\u001b[32m    323\u001b[39m     zamba,\n\u001b[32m    324\u001b[39m     zamba2,\n\u001b[32m    325\u001b[39m     zoedepth,\n\u001b[32m    326\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1559\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1533\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1632\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:152\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available 🐸TTS models\n",
    "print(TTS().list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > You must confirm the following:\n",
      " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
      " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.87G/1.87G [00:49<00:00, 37.6MiB/s]\n",
      "100%|██████████| 4.37k/4.37k [00:00<00:00, 19.2kiB/s]\n",
      "100%|██████████| 361k/361k [00:00<00:00, 903kiB/s] \n",
      "100%|██████████| 32.0/32.0 [00:00<00:00, 101iB/s]\n",
      "100%|██████████| 7.75M/7.75M [00:19<00:00, 34.8MiB/s]"
     ]
    }
   ],
   "source": [
    "# TTS 모델 불러오기\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc394f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./resources/xtts_output.mp3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음성 합성\n",
    "tts.tts_to_file(\n",
    "    text=\"안녕하세요 배우 고윤정입니다 만나서 반갑습니다.\",\n",
    "    speaker_wav=\"./resources/고윤정.mp3\",\n",
    "    language=\"ko\",\n",
    "    file_path=\"./resources/xtts_output.mp3\",\n",
    "    speed=1.3,             # 발화 속도 조절\n",
    "    temperature=0.75,      # 발화 온도 조절\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad9139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./resources/xtts_output2.mp3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음성 합성\n",
    "tts.tts_to_file(\n",
    "    text=\"지겨운가요 힘든가요 숨이 턱까지 찼나요 할 수 없죠 어차피 시작해 버린 것을\",\n",
    "    speaker_wav=\"./resources/고윤정.mp3\",\n",
    "    language=\"ko\",\n",
    "    file_path=\"./resources/xtts_output2.mp3\",\n",
    "    speed=1.3,             # 발화 속도 조절\n",
    "    temperature=0.75,      # 발화 온도 조절\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
