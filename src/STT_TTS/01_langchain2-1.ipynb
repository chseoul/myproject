{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e977ab",
   "metadata": {},
   "source": [
    "# 2. 페르소나 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65270e10",
   "metadata": {},
   "source": [
    "## 0) 환경변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ab8006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffdedc",
   "metadata": {},
   "source": [
    "# 챗봇 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acfb8e9",
   "metadata": {},
   "source": [
    "## 1) 구성 요소 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc6139",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1527ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='좋은 아침입니다! 오늘 하루도 잘 보내시길 바랍니다. 무엇을 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 12, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BbnmDEMA6RpTZGVDAIGbKnLOitxur', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--2bc81d7d-c335-4660-9ab7-79b48daa14bb-0' usage_metadata={'input_tokens': 12, 'output_tokens': 23, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Model 생성\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # 비용 gpt-4.1-nano < gpt-4o-mini < gpt-4\n",
    "    temperature=0.5       # 창의성 정도(0~1 사이의 값. 1에 가까울수록 창의적인 답변)\n",
    ")\n",
    "response = model.invoke(\"좋은 아침!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31ff37",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd58d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['history', 'input'] input_types={'history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021FFD5EDB20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 동기부여 된 AI 어시스턴트입니다. 사용자에게 정확하고 도움이 되는 답변을 제공하세요. 사용자의 질문을 영어로 번역해서 제공한 후에 영어로 답변합니다.'), additional_kwargs={}), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system_prompt = \"당신은 동기부여 된 AI 어시스턴트입니다. 사용자에게 정확하고 도움이 되는 답변을 제공하세요. 사용자의 질문을 영어로 번역해서 제공한 후에 영어로 답변합니다.\"\n",
    "\n",
    "# 히스토리를 반영한 Prompt 생성\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cfce53",
   "metadata": {},
   "source": [
    "### OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1a59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# OutputParser 생성\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681d14d",
   "metadata": {},
   "source": [
    "## 2) Runnable 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4713e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable 생성\n",
    "runnable = prompt | model | output_parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9275627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# 히스토리가 저장될 변수 생성\n",
    "store = {}  \n",
    "\n",
    "# 세션 ID별 히스토리를 가져오는 함수\n",
    "def get_session_history(session_id):\n",
    "    # store의 key에 session_id가 없는 경우 session_id를 key에 추가\n",
    "    if session_id not in store: \n",
    "        store[session_id] = ChatMessageHistory()\n",
    "        \n",
    "    # session_id 키의 값을 반환\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cda69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Chain 생성\n",
    "chain = (\n",
    "    RunnableWithMessageHistory(          # RunnableWithMessageHistory 객체 생성\n",
    "        runnable,                        # 실행할 Runnable 객체\n",
    "        get_session_history,             # 세션 ID별 히스토리를 가져오는 함수\n",
    "        input_messages_key=\"input\",      # 입력 메시지의 키\n",
    "        history_messages_key=\"history\",  # 기록 메시지의 키\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a0d41",
   "metadata": {},
   "source": [
    "## 챗봇 1 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ced6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]: 안녕, 즐거운 밤이야!\n",
      "[AI]: Hello, it's a pleasant night! \n",
      "\n",
      "I'm glad to hear that! How can I assist you tonight?\n",
      "[USER]: 오늘 날씨가 좋더라!\n",
      "[AI]: The weather was nice today!\n",
      "\n",
      "That's great to hear! Nice weather can really lift your spirits. Did you get a chance to enjoy it outside?\n",
      "[USER]: q\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# 무한 루프\n",
    "while True:\n",
    "    ## 사용자 입력 받기\n",
    "    question = input(\"[USER] \")\n",
    "    print(f\"[USER]: {question}\")\n",
    "    ## 종료 조건\n",
    "    if question == \"q\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "    ## 응답 받기\n",
    "    response = chain.invoke(\n",
    "        {\"input\": question},\n",
    "        {\"configurable\": {\"session_id\": \"user1\"}}\n",
    "    )\n",
    "    print(f\"[AI]: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
